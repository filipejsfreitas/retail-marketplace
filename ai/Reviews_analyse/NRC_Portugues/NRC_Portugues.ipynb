{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPGqo8Xt6FYb"
      },
      "source": [
        "# Criação dicionário NRC, a partir da lista fornecida\n",
        "\n",
        "NOTA:é necessario porque o modulo NRCLex não esta disponivel para portugues.\n",
        "    -- Este ficheiro permitiu obter O ficheiro NTRC_portuguese.json que contem o dicionario de palavras em portugues ja tratado\n",
        "Definição da função que avalia uma frase lematizada, usando um dicionário criado por nós com base no corpus fornecido pelo ``NRCLex`` em português."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "-YfgcL5pKT5s",
        "outputId": "aa9107a7-3804-4f51-fe52-ad6b9ae33e29"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wordEN</th>\n",
              "      <th>word</th>\n",
              "      <th>emotion</th>\n",
              "      <th>emotion_intensity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>torment</td>\n",
              "      <td>tormento</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wrath</td>\n",
              "      <td>ira</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vicious</td>\n",
              "      <td>vicioso</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>massacre</td>\n",
              "      <td>massacre</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>threatening</td>\n",
              "      <td>ameaçador</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pissoff</td>\n",
              "      <td>não me chateies</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>abhorrent</td>\n",
              "      <td>repugnante</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bloodthirsty</td>\n",
              "      <td>sanguinário</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fighting</td>\n",
              "      <td>combate</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>annihilated</td>\n",
              "      <td>aniquilado</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>attacking</td>\n",
              "      <td>atacante</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>angriest</td>\n",
              "      <td>mais raivoso</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          wordEN             word emotion  emotion_intensity_score\n",
              "0        torment         tormento   anger                    0.885\n",
              "1          wrath              ira   anger                    0.885\n",
              "2        vicious          vicioso   anger                    0.884\n",
              "3       massacre         massacre   anger                    0.882\n",
              "4    threatening        ameaçador   anger                    0.882\n",
              "5        pissoff  não me chateies   anger                    0.875\n",
              "6      abhorrent       repugnante   anger                    0.875\n",
              "7   bloodthirsty      sanguinário   anger                    0.875\n",
              "8       fighting          combate   anger                    0.868\n",
              "9    annihilated       aniquilado   anger                    0.865\n",
              "10     attacking         atacante   anger                    0.865\n",
              "11      angriest     mais raivoso   anger                    0.864"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#importar o dataset do NRCLex em português\n",
        "\n",
        "filepath = 'NRCPortugues.txt'\n",
        "emolex_df = pd.read_csv(filepath,   names=[\"wordEN\", \"word\", \"emotion\", \"emotion_intensity_score\"], index_col=False, skiprows=45, sep='\\t')\n",
        "emolex_df.head(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWFjWMYoRCxg"
      },
      "source": [
        "Criação do dicionário com as palavras do dataset + os sentimentos associados às mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQmJqUfBKuXP",
        "outputId": "4057b0b9-252d-430e-9914-0cad4041df2c"
      },
      "outputs": [],
      "source": [
        "emolex_df = emolex_df.drop(columns = 'wordEN')\n",
        "\n",
        "lex_dic = {}\n",
        "x=0\n",
        "for i in emolex_df['word']:\n",
        "    lex_dic[i]=[]\n",
        "\n",
        "for i,row in emolex_df.iterrows():\n",
        "    \n",
        "    lex_dic[row['word']].append( (row['emotion'], row['emotion_intensity_score']) )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWzF9-2wRM1P"
      },
      "source": [
        "Mapeamento dos sentimentos associados a cada palavra em **positivo** e **negativo**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m_K-oRreMm-G"
      },
      "outputs": [],
      "source": [
        "lp =['anticipation','joy', 'surprise', 'trust']\n",
        "ln =['anger', 'disgust', 'fear', 'sadness']\n",
        "dic = {}\n",
        "for i in lex_dic:\n",
        "    dic[i]='a'\n",
        "\n",
        "for i in lex_dic:\n",
        "    x=lex_dic[i]\n",
        "    contp=0\n",
        "    contn=0\n",
        "    for k in x:\n",
        "        (e,c)=k\n",
        "        if e in lp:\n",
        "            contp = contp + c\n",
        "        elif e in ln:\n",
        "            contn = contn + c\n",
        "    if(contp > contn):\n",
        "        dic[i]='positivo'\n",
        "    else :\n",
        "        dic[i]='negativo'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardar os dados lidos do ficheiro texto num dicionario, que classifica cada palavra num dado sentimento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "85bFuBD1yiBC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "file = open(\"NRC_portuguese.json\", \"w\")\n",
        "json.dump(dic,file)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ler o dicionario de palavras em Portugues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = open(\"NRC_portuguese.json\", \"r\")\n",
        "NRC_file = file.read()\n",
        "NRC = json.loads(NRC_file)\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type (NRC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Para classificação do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVvGR_uU6FYb",
        "outputId": "bfa251a6-7a39-4bae-aa2a-8409385f3abb"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'pt_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26556/2702723153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mtexto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Não deixe que as pessoas te façam desistir daquilo que você mais quer na vida. Acredita. Lutar. Conquistar. E acima de tudo, se feliz!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataPrep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mavalia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26556/2702723153.py\u001b[0m in \u001b[0;36mdataPrep\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdataPrep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pt_core_news_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'pt_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "# Função que faz lematização, tokenização, retira pontuação e stop words, coloca o texto em minusculas\n",
        "import spacy\n",
        "def dataPrep(review):\n",
        "    \n",
        "    nlp = spacy.load(\"pt_core_news_sm\")\n",
        "    doc = nlp(review)\n",
        "    res = \" \".join([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct])   \n",
        "    \n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "def avalia(review):\n",
        "    \n",
        "    d = {'positive': 0, 'negative': 0, 'fear': 0, 'anger' :0, 'antecipation': 0, 'surprise':0 , 'sadness':0, 'disgust':0, 'joy':0}\n",
        "   \n",
        " \n",
        "    for i in range(len(review)):\n",
        "        #print(frase[i])\n",
        "        word = review[i]\n",
        "\n",
        "        ## Verificar se a word esta no corpus\n",
        "        if word in NRC:\n",
        "          emotion = NRC[word]\n",
        "          d[emotion] = d[emotion] + 1\n",
        "         \n",
        "    ## Retorna o dicionario com as emoções ordenado\n",
        "    return {k: d[k] for k in sorted(d)}\n",
        "    \n",
        "\n",
        "\n",
        "texto = \"Não deixe que as pessoas te façam desistir daquilo que você mais quer na vida. Acredita. Lutar. Conquistar. E acima de tudo, se feliz!\"\n",
        "res = dataPrep(texto)\n",
        "print(res)\n",
        "avalia(res.split(\" \"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1OoI_f6FYc"
      },
      "source": [
        "# Classificação do Dataset\n",
        "\n",
        "Estamos a assumir que os negativos (0) vão despoletar reação e que os positivos (1) não vão despoletar reação."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NRC .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
